{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:49:52.352393Z","iopub.status.busy":"2023-06-26T05:49:52.352002Z","iopub.status.idle":"2023-06-26T05:49:56.317602Z","shell.execute_reply":"2023-06-26T05:49:56.316462Z","shell.execute_reply.started":"2023-06-26T05:49:52.352368Z"},"trusted":true},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import os\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:49:56.324159Z","iopub.status.busy":"2023-06-26T05:49:56.323480Z","iopub.status.idle":"2023-06-26T05:50:20.791595Z","shell.execute_reply":"2023-06-26T05:50:20.790482Z","shell.execute_reply.started":"2023-06-26T05:49:56.324125Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\n","Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -U accelerate>=0.20.1\n","!pip install --upgrade accelerate"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:20.795602Z","iopub.status.busy":"2023-06-26T05:50:20.795292Z","iopub.status.idle":"2023-06-26T05:50:20.804991Z","shell.execute_reply":"2023-06-26T05:50:20.804006Z","shell.execute_reply.started":"2023-06-26T05:50:20.795574Z"},"trusted":true},"outputs":[{"data":{"text/html":["<script>Jupyter.notebook.kernel.restart()</script>"],"text/plain":["<IPython.core.display.HTML object>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.core.display import HTML\n","HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:20.809451Z","iopub.status.busy":"2023-06-26T05:50:20.809163Z","iopub.status.idle":"2023-06-26T05:50:35.125516Z","shell.execute_reply":"2023-06-26T05:50:35.124378Z","shell.execute_reply.started":"2023-06-26T05:50:20.809428Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.10/site-packages (4.30.1)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.15.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (5.4.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.5.5)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.3.1)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.1.99)\n","Requirement already satisfied: protobuf<=3.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: portalocker, sacrebleu\n","Successfully installed portalocker-2.7.0 sacrebleu-2.3.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n","0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n"]}],"source":["! pip install datasets transformers[sentencepiece] sacrebleu\n","!apt install git-lfs"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:35.127722Z","iopub.status.busy":"2023-06-26T05:50:35.127402Z","iopub.status.idle":"2023-06-26T05:50:36.818097Z","shell.execute_reply":"2023-06-26T05:50:36.817190Z","shell.execute_reply.started":"2023-06-26T05:50:35.127692Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38285da1363f46f69dfb41aeb836596f","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_metric\n","\n","metric = load_metric(\"sacrebleu\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:36.820061Z","iopub.status.busy":"2023-06-26T05:50:36.819414Z","iopub.status.idle":"2023-06-26T05:50:38.145739Z","shell.execute_reply":"2023-06-26T05:50:38.143905Z","shell.execute_reply.started":"2023-06-26T05:50:36.820028Z"},"trusted":true},"outputs":[{"data":{"text/plain":["100"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Create a DataFrame with two columns, \"English\" and \"Paraphrase\".\n","df = pd.read_csv(\"/kaggle/input/para-100/para_100k (1).csv\")\n","df_valid = pd.read_csv(\"/kaggle/input/para-100/test(1).csv\")\n","\n","# Create a new column named \"Translate\".\n","df[\"Translate\"] = df[[\"eng\", \"para\"]].apply(lambda x: dict(zip([\"eng\", \"para\"], x)), axis=1)\n","df_valid[\"Translate\"] = df_valid[[\"eng\", \"para\"]].apply(lambda x: dict(zip([\"eng\", \"para\"], x)), axis=1)\n","len(df_valid)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:38.147824Z","iopub.status.busy":"2023-06-26T05:50:38.147442Z","iopub.status.idle":"2023-06-26T05:50:38.205800Z","shell.execute_reply":"2023-06-26T05:50:38.204737Z","shell.execute_reply.started":"2023-06-26T05:50:38.147792Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Translate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'eng': 'the second requirement is the one at ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'eng': 'he even brought his favorite buddy be...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'eng': 'move it line up in front of mrs bowa'...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'eng': 'the priest and the mage are playing g...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'eng': 'more constructs in one place than had...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>{'eng': 'it was night and the lanterns were li...</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>{'eng': 'in the interests of clarity that regu...</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>{'eng': 'mara gasped for breath but none came ...</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>{'eng': 'but you are right mandy bronson does ...</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>{'eng': 'indicates the requested operation wou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100000 rows × 1 columns</p>\n","</div>"],"text/plain":["                                               Translate\n","0      {'eng': 'the second requirement is the one at ...\n","1      {'eng': 'he even brought his favorite buddy be...\n","2      {'eng': 'move it line up in front of mrs bowa'...\n","3      {'eng': 'the priest and the mage are playing g...\n","4      {'eng': 'more constructs in one place than had...\n","...                                                  ...\n","99995  {'eng': 'it was night and the lanterns were li...\n","99996  {'eng': 'in the interests of clarity that regu...\n","99997  {'eng': 'mara gasped for breath but none came ...\n","99998  {'eng': 'but you are right mandy bronson does ...\n","99999  {'eng': 'indicates the requested operation wou...\n","\n","[100000 rows x 1 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = df.drop([\"eng\",\"Unnamed: 0\", \"para\"], axis=1)\n","df = df.dropna()\n","df_valid = df_valid.drop([\"eng\",\"Unnamed: 0\", \"para\"], axis=1)\n","df_valid = df_valid.dropna()\n","\n","df"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:38.207690Z","iopub.status.busy":"2023-06-26T05:50:38.207238Z","iopub.status.idle":"2023-06-26T05:50:38.317748Z","shell.execute_reply":"2023-06-26T05:50:38.316849Z","shell.execute_reply.started":"2023-06-26T05:50:38.207655Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset,Dataset,DatasetDict\n","\n","data_train = Dataset.from_pandas(df)\n","data_valid = Dataset.from_pandas(df_valid)\n","data_train = DatasetDict({\"train\":data_train, \"validation\": data_valid})\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:38.319514Z","iopub.status.busy":"2023-06-26T05:50:38.319081Z","iopub.status.idle":"2023-06-26T05:50:38.326553Z","shell.execute_reply":"2023-06-26T05:50:38.325467Z","shell.execute_reply.started":"2023-06-26T05:50:38.319482Z"},"trusted":true},"outputs":[],"source":["max_input_length = 512\n","max_target_length = 512\n","source_lang = \"eng\"\n","target_lang = \"para\"\n","\n","def preprocess_function(examples):\n","    inputs = [ex[source_lang] for ex in examples[\"Translate\"]]\n","    targets = [ex[target_lang] for ex in examples[\"Translate\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length,padding = \"max_length\", truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=max_target_length,padding = \"max_length\", truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:38.331540Z","iopub.status.busy":"2023-06-26T05:50:38.330897Z","iopub.status.idle":"2023-06-26T05:50:41.454343Z","shell.execute_reply":"2023-06-26T05:50:41.453392Z","shell.execute_reply.started":"2023-06-26T05:50:38.331502Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efb410699138454e950458abb1444e32","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bef35b30bf6a46ea96c6ac5e87cd4f7d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12b4aaf0a63a40388f4c3ac744ceb5fe","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"137c9a5fff704ebc8afd8d44fb8cf447","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"Tri1/12-18-finetuned-eng-to-para\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:50:41.456580Z","iopub.status.busy":"2023-06-26T05:50:41.455890Z","iopub.status.idle":"2023-06-26T05:51:40.694064Z","shell.execute_reply":"2023-06-26T05:51:40.693142Z","shell.execute_reply.started":"2023-06-26T05:50:41.456545Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dffa9eaa40c24820918aefcea4f5e0f1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c412a1b3f04c4e86a0edb3d97353439c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = data_train.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:51:40.696144Z","iopub.status.busy":"2023-06-26T05:51:40.695550Z","iopub.status.idle":"2023-06-26T05:51:40.705290Z","shell.execute_reply":"2023-06-26T05:51:40.704420Z","shell.execute_reply.started":"2023-06-26T05:51:40.696110Z"},"trusted":true},"outputs":[],"source":["tokenized_datasets = tokenized_datasets.remove_columns([\"Translate\"])\n","tokenized_datasets.set_format(\"torch\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:51:40.707208Z","iopub.status.busy":"2023-06-26T05:51:40.706856Z","iopub.status.idle":"2023-06-26T05:51:40.713899Z","shell.execute_reply":"2023-06-26T05:51:40.712169Z","shell.execute_reply.started":"2023-06-26T05:51:40.707178Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(tokenized_datasets, shuffle=True, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T05:51:40.715922Z","iopub.status.busy":"2023-06-26T05:51:40.715173Z"},"trusted":true},"outputs":[],"source":["!pip install -U accelerate>=0.20.1\n","!pip install --upgrade accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","model_checkpoint = \"Tri1/12-18-finetuned-eng-to-para\"\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 16\n","model_name = \"18-24\"\n","args = Seq2SeqTrainingArguments(\n","    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=6,\n","    predict_with_generate=True,\n","    fp16=True,\n","    push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from huggingface_hub import notebook_login\n","from huggingface_hub import login\n","login(token = \"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\")\n","notebook_login()\n","import wandb\n","wandb.login(key=\"cbcabc061fb4a62d6ebeae24db563b71d7747fb6\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.push_to_hub()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
